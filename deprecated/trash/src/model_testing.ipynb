{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/DeepenData/.miniconda/envs/geo/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device = 'cuda:0'\n"
     ]
    }
   ],
   "source": [
    "from acevedo_clss_and_fcns import * \n",
    "from torch_geometric.nn import GNNExplainer\n",
    "from torch_scatter import scatter\n",
    "\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.init()\n",
    "    if torch.cuda.is_initialized():\n",
    "        device = 'cuda:0'\n",
    "#device = torch.device(device)\n",
    "print(f\"{device = }\")\n",
    "loader_path = \"./results/dataloaders/loader_Concen_plus_Fluxes.pt\"\n",
    "\n",
    "\n",
    "loader = torch.load(loader_path)\n",
    "a_batch         = next(iter(loader.get_train_loader()))\n",
    "a_graph         = a_batch[0]\n",
    "batch_size      = len(a_batch.ptr)-1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 2])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache() \n",
    "class GIN_classifier_to_explain_v2(torch.nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        n_classes: int,\n",
    "        n_nodes : int, \n",
    "        num_features : int, \n",
    "        out_channels: int = 8,\n",
    "        dropout : float = 0.05, \n",
    "        hidden_dim : int = 8, \n",
    "        LeakyReLU_slope : float = 0.01,\n",
    "        num_layers: int = 2\n",
    "    ):\n",
    "        super(GIN_classifier_to_explain_v2, self).__init__() # TODO: why SUPER gato? \n",
    "        self.n_nodes = n_nodes\n",
    "        self.n_classes = n_classes\n",
    "        self.dropout = dropout\n",
    "        self.num_features = num_features\n",
    "        self.out_channels = out_channels\n",
    "        self.GIN_layers =  GIN(in_channels= num_features, hidden_channels= hidden_dim, num_layers= num_layers, \n",
    "                               out_channels= out_channels, dropout=dropout,  jk=None, act='LeakyReLU', act_first = False)              \n",
    "        self.FC1          = Linear(in_features=out_channels, out_features=1, bias=True)\n",
    "        self.FC2          = Linear(in_features= self.n_nodes, out_features=self.n_classes, bias=True)\n",
    "        #self.FC          = Linear(in_features=out_channels, out_features=1, bias=True)           \n",
    "           \n",
    "        self.leakyrelu  = LeakyReLU(LeakyReLU_slope)#.to('cuda')\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        batch_size = batch.unique().__len__()\n",
    "\n",
    "        x     = self.GIN_layers(x, edge_index)\n",
    "        x     = x.reshape(batch_size, self.n_nodes, self.out_channels)\n",
    "        x     = self.FC1(self.leakyrelu(x))\n",
    "        x     = x.reshape(batch_size,  self.n_nodes)       \n",
    "        x     = self.FC2(self.leakyrelu(x))    \n",
    "\n",
    "        return  x #torch.nn.functional.log_softmax(x, dim=1)\n",
    "    \n",
    "model           = GIN_classifier_to_explain_v2(\n",
    "                                            n_nodes = a_graph.num_nodes, \n",
    "                                            num_features = a_graph.num_node_features, \n",
    "                                            n_classes = a_graph.num_classes,\n",
    "                                            hidden_dim=2).to(device, non_blocking=True).to(device)\n",
    "\n",
    "a_batch.to(device)\n",
    "model(a_batch.x, a_batch.edge_index, a_batch.batch).shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain graph: 100%|██████████| 2/2 [00:00<00:00, 500.60it/s]\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache() \n",
    "explainer                 = GNNExplainer(model, epochs=2, num_hops = None, lr=0.002).to(device, non_blocking=True)\n",
    "#node_feat_mask, edge_mask = explainer.explain_graph(a_batch.x, a_batch.edge_index)\n",
    "node_feat_mask, edge_mask = explainer.explain_graph(a_batch[0].x, a_batch[0].edge_index)\n",
    "\n",
    "#node_feat_mask.shape, edge_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain graph: 100%|██████████| 2/2 [00:00<00:00, 299.57it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([]), torch.Size([53122]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_feat_mask, edge_mask = explainer.explain_graph(a_batch[0].x, a_batch[0].edge_index)\n",
    "node_feat_mask.shape, edge_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.48584098, 0.5127498)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_mask.cpu().numpy().min(), edge_mask.cpu().numpy().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Explain graph: 100%|██████████| 2/2 [00:00<00:00, 49.76it/s]\n"
     ]
    }
   ],
   "source": [
    "class GIN_classifier_to_explain(torch.nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        batch_size,\n",
    "        #target_node_idx: int,\n",
    "        n_nodes : int, \n",
    "        num_features : int, \n",
    "        out_channels: int = 8,\n",
    "        dropout : float = 0.05, \n",
    "        hidden_dim : int = 8, \n",
    "        LeakyReLU_slope : float = 0.01,\n",
    "\n",
    "        num_layers: int = 4\n",
    "    ):\n",
    "        super(GIN_classifier_to_explain, self).__init__() # TODO: why SUPER gato? \n",
    "        self.n_nodes = n_nodes\n",
    "        self.dropout = dropout\n",
    "        self.num_features = num_features\n",
    "        #self.target_node_idx = target_node_idx\n",
    "        self.out_channels = out_channels\n",
    "        self.batch_size   = batch_size\n",
    "        \n",
    "        self.GIN_layers =  GIN(in_channels= num_features, hidden_channels= hidden_dim, num_layers= num_layers, \n",
    "                               out_channels= out_channels, dropout=dropout,  jk=None, act='LeakyReLU', act_first = False)      \n",
    "        \n",
    "        self.FC1        = Linear(in_features=out_channels, out_features=1, bias=True)\n",
    "        self.FC2        = Linear(in_features=self.n_nodes, out_features=2, bias=True)      \n",
    "        self.leakyrelu  = LeakyReLU(LeakyReLU_slope)#.to('cuda')\n",
    "    def forward(self, x, edge_index, batch):\n",
    "\n",
    "\n",
    "        x     = self.GIN_layers(x, edge_index)\n",
    "        x     = x.reshape(self.batch_size, self.n_nodes, self.out_channels)\n",
    "        x     = self.FC1(self.leakyrelu(x))\n",
    "        x     = x.reshape(self.batch_size,  self.n_nodes)              \n",
    "        #x     = self.FC2(self.leakyrelu(x))\n",
    "        #x     = x.reshape(self.batch_size, 2)\n",
    "        return   x #torch.nn.functional.log_softmax(x, dim=1).squeeze()\n",
    "    \n",
    "model           = GIN_classifier_to_explain(batch_size = 64,\n",
    "                                            n_nodes = a_graph.num_nodes, \n",
    "                                            num_features = a_graph.num_node_features, \n",
    "                                            #n_classes = a_graph.num_classes,\n",
    "                                            hidden_dim=2).to(device, non_blocking=True).to(device)\n",
    "a_batch.to(device)\n",
    "model(a_batch.x, a_batch.edge_index, a_batch.batch).shape\n",
    "explainer                 = GNNExplainer(model, epochs=2, num_hops = None, lr=0.002).to(device, non_blocking=True)\n",
    "node_feat_mask, edge_mask = explainer.explain_graph(a_batch.x, a_batch.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[64, 12228, 8]' is invalid for input of size 97824",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m node_feat_mask, edge_mask \u001b[39m=\u001b[39m explainer\u001b[39m.\u001b[39;49mexplain_graph(a_batch[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mx, a_batch[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49medge_index)\n",
      "File \u001b[0;32m/DeepenData/.miniconda/envs/geo/lib/python3.9/site-packages/torch_geometric/nn/models/gnn_explainer.py:143\u001b[0m, in \u001b[0;36mGNNExplainer.explain_graph\u001b[0;34m(self, x, edge_index, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m batch \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], dtype\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m, device\u001b[39m=\u001b[39mx\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    142\u001b[0m \u001b[39m# Get the initial prediction.\u001b[39;00m\n\u001b[0;32m--> 143\u001b[0m prediction \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_initial_prediction(x, edge_index, batch\u001b[39m=\u001b[39;49mbatch,\n\u001b[1;32m    144\u001b[0m                                          \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    146\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initialize_masks(x, edge_index)\n\u001b[1;32m    147\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto(x\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[0;32m/DeepenData/.miniconda/envs/geo/lib/python3.9/site-packages/torch/autograd/grad_mode.py:28\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     26\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     27\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m():\n\u001b[0;32m---> 28\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/DeepenData/.miniconda/envs/geo/lib/python3.9/site-packages/torch_geometric/nn/models/explainer.py:233\u001b[0m, in \u001b[0;36mExplainer.get_initial_prediction\u001b[0;34m(self, x, edge_index, batch, **kwargs)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[39m@torch\u001b[39m\u001b[39m.\u001b[39mno_grad()\n\u001b[1;32m    230\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_initial_prediction\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor, edge_index: Tensor,\n\u001b[1;32m    231\u001b[0m                            batch: Optional[Tensor] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    232\u001b[0m     \u001b[39mif\u001b[39;00m batch \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 233\u001b[0m         out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x, edge_index, batch, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    234\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m         out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(x, edge_index, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/DeepenData/.miniconda/envs/geo/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [18], line 34\u001b[0m, in \u001b[0;36mGIN_classifier_to_explain.forward\u001b[0;34m(self, x, edge_index, batch)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, edge_index, batch):\n\u001b[1;32m     33\u001b[0m     x     \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mGIN_layers(x, edge_index)\n\u001b[0;32m---> 34\u001b[0m     x     \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39;49mreshape(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_size, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_nodes, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_channels)\n\u001b[1;32m     35\u001b[0m     x     \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mFC1(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleakyrelu(x))\n\u001b[1;32m     36\u001b[0m     x     \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mreshape(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size,  \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_nodes)              \n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[64, 12228, 8]' is invalid for input of size 97824"
     ]
    }
   ],
   "source": [
    "node_feat_mask, edge_mask = explainer.explain_graph(a_batch[0].x, a_batch[0].edge_index)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('geo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ccb92c3caf64d15d8cccade25008a463e602c087926676408820d80b4769698"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
