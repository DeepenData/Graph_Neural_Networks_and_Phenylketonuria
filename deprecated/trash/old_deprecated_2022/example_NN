digraph {
	graph [size="12,12"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140414639204848 [label="
 (128, 1)" fillcolor=darkolivegreen1]
	140414639527056 [label=AddmmBackward0]
	140414639526432 -> 140414639527056
	140417219212608 [label="layer_out.bias
 (1)" fillcolor=lightblue]
	140417219212608 -> 140414639526432
	140414639526432 [label=AccumulateGrad]
	140414639527200 -> 140414639527056
	140414639527200 [label=NativeBatchNormBackward0]
	140414639527824 -> 140414639527200
	140414639527824 [label=ReluBackward0]
	140414638715136 -> 140414639527824
	140414638715136 [label=AddmmBackward0]
	140414638715232 -> 140414638715136
	140417219212528 [label="layer_2.bias
 (64)" fillcolor=lightblue]
	140417219212528 -> 140414638715232
	140414638715232 [label=AccumulateGrad]
	140414638715184 -> 140414638715136
	140414638715184 [label=NativeBatchNormBackward0]
	140414638715328 -> 140414638715184
	140414638715328 [label=ReluBackward0]
	140414638715616 -> 140414638715328
	140414638715616 [label=AddmmBackward0]
	140414638715712 -> 140414638715616
	140418448438112 [label="layer_1.bias
 (64)" fillcolor=lightblue]
	140418448438112 -> 140414638715712
	140414638715712 [label=AccumulateGrad]
	140414638715664 -> 140414638715616
	140414638715664 [label=TBackward0]
	140414638715760 -> 140414638715664
	140418636605216 [label="layer_1.weight
 (64, 20)" fillcolor=lightblue]
	140418636605216 -> 140414638715760
	140414638715760 [label=AccumulateGrad]
	140414638715376 -> 140414638715184
	140417219213088 [label="batchnorm1.weight
 (64)" fillcolor=lightblue]
	140417219213088 -> 140414638715376
	140414638715376 [label=AccumulateGrad]
	140414638715424 -> 140414638715184
	140417219211888 [label="batchnorm1.bias
 (64)" fillcolor=lightblue]
	140417219211888 -> 140414638715424
	140414638715424 [label=AccumulateGrad]
	140414638715040 -> 140414638715136
	140414638715040 [label=TBackward0]
	140414638715520 -> 140414638715040
	140417219212368 [label="layer_2.weight
 (64, 64)" fillcolor=lightblue]
	140417219212368 -> 140414638715520
	140414638715520 [label=AccumulateGrad]
	140414639526096 -> 140414639527200
	140417219211568 [label="batchnorm2.weight
 (64)" fillcolor=lightblue]
	140417219211568 -> 140414639526096
	140414639526096 [label=AccumulateGrad]
	140414638714944 -> 140414639527200
	140417219211728 [label="batchnorm2.bias
 (64)" fillcolor=lightblue]
	140417219211728 -> 140414638714944
	140414638714944 [label=AccumulateGrad]
	140414639526048 -> 140414639527056
	140414639526048 [label=TBackward0]
	140414638715280 -> 140414639526048
	140417219212688 [label="layer_out.weight
 (1, 64)" fillcolor=lightblue]
	140417219212688 -> 140414638715280
	140414638715280 [label=AccumulateGrad]
	140414639527056 -> 140414639204848
}
