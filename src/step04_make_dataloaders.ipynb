{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/DeepenData/.miniconda/envs/geo/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from acevedo_clss_and_fcns import *\n",
    "\n",
    "\n",
    "def make_graphs_list(pyg_graph_in,target_list, mask_target:bool=False, mask_number:float = 1e-10):\n",
    "    \n",
    "    pyg_graph = copy.deepcopy(pyg_graph_in)\n",
    "    graphs_list = []\n",
    "    \n",
    "    \n",
    "    for i in range(pyg_graph.x.shape[1]):\n",
    "    \n",
    "        \n",
    "        new_pyg_data  = Data(x =  pyg_graph.x[:,i].reshape(pyg_graph.num_nodes, 1),  y = pyg_graph.y[i], \n",
    "                            edge_index = pyg_graph.edge_index)\n",
    "        new_pyg_data.num_classes = 2\n",
    "        \n",
    "        \n",
    "        if mask_target:\n",
    "            for n in target_list:\n",
    "                new_pyg_data.x[n,:] = mask_number\n",
    "                #new_pyg_data.x[target_node_1,:] = mask_number\n",
    "                #new_pyg_data.x[target_node_2,:] = mask_number        \n",
    "        \n",
    "        graphs_list.append(new_pyg_data) \n",
    "    return graphs_list\n",
    "\n",
    "\n",
    "grafo_nx   = nx.read_gpickle( \"./results/graphs/NX_recon_graph.gpickle\")\n",
    "phe_L_c    = list(grafo_nx.nodes).index('phe_L_c')\n",
    "tyr_L_c    = list(grafo_nx.nodes).index('tyr_L_c')\n",
    "r0399      = list(grafo_nx.nodes).index('r0399')\n",
    "PHETHPTOX2 = list(grafo_nx.nodes).index('PHETHPTOX2')\n",
    "PYG_graph_only_Concen         = torch.load(\"./results/graphs/PYG_graph_only_Concen.pt\")\n",
    "PYG_graph_only_Fluxes          = torch.load(\"./results/graphs/PYG_graph_only_Fluxes.pt\")\n",
    "PYG_graph_Concen_plus_Fluxes  = torch.load(\"./results/graphs/PYG_graph_Concen_plus_Fluxes.pt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_partition , second_partition = bipartite.sets(grafo_nx)\n",
    "\n",
    "if first_partition.__len__() > second_partition.__len__():\n",
    "    rxn_partition = first_partition\n",
    "    met_partition = second_partition\n",
    "else:\n",
    "    rxn_partition = second_partition \n",
    "    met_partition = first_partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_list =  np.array(list(nx.get_node_attributes(grafo_nx, \"bipartite\").values()))\n",
    "mask_rxns      =  partition_list.astype(bool)\n",
    "mask_mets      =  np.invert(partition_list.astype(bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs_list_PYG_graph_only_Concen        = make_graphs_list(PYG_graph_only_Concen, target_list = [phe_L_c, tyr_L_c], mask_target = True)\n",
    "graphs_list_PYG_graph_only_Fluxes        = make_graphs_list(PYG_graph_only_Fluxes, target_list = [r0399, PHETHPTOX2], mask_target = True)\n",
    "graphs_list_PYG_graph_Concen_plus_Fluxes = make_graphs_list(PYG_graph_Concen_plus_Fluxes, \n",
    "                                                            target_list = [phe_L_c, tyr_L_c, r0399, PHETHPTOX2], mask_target = True)\n",
    "\n",
    "loader_only_Concen                 = batch_loader(graphs_list_PYG_graph_only_Concen, batch_size= 4*32, validation_percent = .4)\n",
    "loader_only_Fluxes                 = batch_loader(graphs_list_PYG_graph_only_Fluxes, batch_size= 4*32, validation_percent = .4)\n",
    "loader_Concen_plus_Fluxes          = batch_loader(graphs_list_PYG_graph_Concen_plus_Fluxes, batch_size= 4*32, validation_percent = .4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_a_graph_from_loader(loader):\n",
    "    \n",
    "    #loader   = loader_only_Concen #torch.load(loader_path)\n",
    "    a_batch  = next(iter(loader.get_train_loader()))\n",
    "    return a_batch[0]\n",
    "\n",
    "\n",
    "x_loader_only_Concen = get_a_graph_from_loader(loader_only_Concen)\n",
    "\n",
    "\n",
    "assert np.unique(\n",
    "    x_loader_only_Concen.x.reshape(len(mask_mets))[mask_mets][\n",
    "    x_loader_only_Concen.x.reshape(len(mask_mets))[mask_mets] > 1e-10]).__len__() > 2\n",
    "\n",
    "assert np.unique(\n",
    "    x_loader_only_Concen.x.reshape(len(mask_mets))[mask_mets][\n",
    "    x_loader_only_Concen.x.reshape(len(mask_mets))[mask_mets] <= 1e-10]).__len__() >= 1\n",
    "\n",
    "#np.array([1.e-10]) in \n",
    "assert np.unique(\n",
    "    x_loader_only_Concen.x.reshape(len(mask_mets))[mask_mets][\n",
    "    x_loader_only_Concen.x.reshape(len(mask_mets))[mask_mets] <= 1e-10]).__len__() <=2\n",
    "\n",
    "\n",
    "assert np.unique(\n",
    "x_loader_only_Concen.x.reshape(len(mask_mets))[mask_mets][\n",
    "    x_loader_only_Concen.x.reshape(len(mask_mets))[mask_mets] <= 1e-10]).sum() < 1e-9\n",
    "\n",
    "\n",
    "assert np.unique(x_loader_only_Concen.x.reshape(len(mask_rxns))[mask_rxns]).__len__() == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_loader_only_Fluxes = get_a_graph_from_loader(loader_only_Fluxes)\n",
    "\n",
    "\n",
    "assert np.unique(x_loader_only_Fluxes.x.reshape(len(mask_mets))[mask_mets]).__len__() == 1\n",
    "assert np.unique(x_loader_only_Fluxes.x.reshape(len(mask_mets))[mask_rxns]).__len__() > 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_loader_Concen_plus_Fluxes = get_a_graph_from_loader(loader_Concen_plus_Fluxes)\n",
    "\n",
    "\n",
    "assert np.unique(\n",
    "    x_loader_Concen_plus_Fluxes.x.reshape(len(mask_mets))[mask_mets][\n",
    "    x_loader_Concen_plus_Fluxes.x.reshape(len(mask_mets))[mask_mets] > 1e-10]).__len__() > 3\n",
    "\n",
    "\n",
    "assert np.unique(\n",
    "    x_loader_Concen_plus_Fluxes.x.reshape(len(mask_mets))[mask_mets][\n",
    "        np.invert(\n",
    "    x_loader_Concen_plus_Fluxes.x.reshape(len(mask_mets))[mask_mets] > 1e-10)]\n",
    "    ).__len__() <=2\n",
    "\n",
    "\n",
    "assert np.unique(\n",
    "    x_loader_Concen_plus_Fluxes.x.reshape(len(mask_mets))[mask_mets][\n",
    "        np.invert(\n",
    "    x_loader_Concen_plus_Fluxes.x.reshape(len(mask_mets))[mask_mets] > 1e-10)]\n",
    "    ).sum() < 1e-9\n",
    "\n",
    "\n",
    "assert np.unique(\n",
    "    x_loader_Concen_plus_Fluxes.x.reshape(len(mask_mets))[mask_rxns][\n",
    "    x_loader_Concen_plus_Fluxes.x.reshape(len(mask_mets))[mask_rxns] > 1e-10]).__len__() > 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(loader_only_Concen, \"./results/dataloaders/MASKED_loader_only_Concen.pt\")\n",
    "torch.save(loader_only_Fluxes, \"./results/dataloaders/MASKED_loader_only_Fluxes.pt\")\n",
    "torch.save(loader_Concen_plus_Fluxes, \"./results/dataloaders/MASKED_loader_Concen_plus_Fluxes.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ccb92c3caf64d15d8cccade25008a463e602c087926676408820d80b4769698"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
