#%%
#from acevedo_clss_and_fcns import *
import torch
from networkx.algorithms import bipartite
import numpy as np
from torch_geometric.loader import DataLoader
from torch.utils.data import RandomSampler
from sklearn.model_selection import train_test_split
import networkx as nx

def make_graphs_list(pyg_graph_in, target_list, mask_target=False, mask_number=1e-10):
    """
    Function to create a list of PyTorch geometric data objects (graphs) 
    from the input graph, with an option to mask certain target nodes.

    Args:
        pyg_graph_in: Input PyTorch Geometric Data object.
        target_list: List of target nodes to mask.
        mask_target: If True, the target nodes will be masked.
        mask_number: The number with which to replace the target nodes 
                     if mask_target is True. 

    Returns:
        graphs_list: List of PyTorch Geometric Data objects.
    """
    import copy
    from torch_geometric.data import Data
    
    # Make a deep copy of the input graph to prevent modifications to the original
    pyg_graph = copy.deepcopy(pyg_graph_in)
    graphs_list = []

    # Iterate over the feature dimension of the node feature matrix 
    for i in range(pyg_graph.x.shape[1]):
        # Create a new PyTorch Geometric Data object for each feature
        new_pyg_data = Data(x=pyg_graph.x[:, i].reshape(pyg_graph.num_nodes, 1), 
                            y=pyg_graph.y[i], 
                            edge_index=pyg_graph.edge_index)
        new_pyg_data.num_classes = 2

        # If mask_target is True, mask the target nodes
        if mask_target:
            for n in target_list:
                new_pyg_data.x[n, :] = mask_number
                
        # Append the new graph to the list
        graphs_list.append(new_pyg_data)
        
    return graphs_list

def get_a_graph_from_loader(loader):
    """
    Function to extract a graph from a loader object.

    Args:
        loader: Loader object that generates batches of data.

    Returns:
        Batch: First batch generated by the loader object.
    """
    # Get the first batch from the loader
    a_batch = next(iter(loader.get_train_loader()))

    # Return the first graph in the batch
    return a_batch[0]

class BatchLoader():
    """
    BatchLoader is a class that helps to generate DataLoader for train, validation, and test sets.

    Attributes:
    ----------
    graphs: list
        The list of input graphs.
    batch_size: int
        The size of each batch of graphs. Default is 32.
    num_samples: int, optional
        The number of samples to draw from the graphs to form a batch. 
        If not provided, all graphs are used.
    validation_percent: float
        The percentage of the dataset to be used for validation and testing. Default is 0.3 (30%).
        
    train_idxs: list
        List of indexes for the training data split.
    val_idxs: list
        List of indexes for the validation data split.
    test_idxs: list
        List of indexes for the test data split.

    Methods:
    -------
    get_train_loader():
        Returns a DataLoader for the training data.
    get_validation_loader():
        Returns a DataLoader for the validation data.
    get_test_loader():
        Returns a DataLoader for the testing data.
    """

    def __init__(self, graphs: list, batch_size: int  =1*32, num_samples:int = None, validation_percent:float = .3):
        self.graphs = graphs
        self.batch_size = batch_size
        self.num_samples = num_samples
        self.validation_percent = validation_percent

        # Splitting the data into train, validation, and test sets.
        self.train_idxs, self.sub_idxs = train_test_split(range(len(self.graphs)), test_size = self.validation_percent)
        self.val_idxs,   self.test_idxs = train_test_split(self.sub_idxs, test_size = self.validation_percent)     

    def get_train_loader(self):
        """
        Generates and returns a DataLoader for the training data.
        """
        train_subset = [self.graphs[i] for i in self.train_idxs]
        sampler      = RandomSampler(train_subset, replacement=False)   
        return  DataLoader(train_subset, batch_size= self.batch_size, sampler = sampler,  drop_last=True)

    def get_validation_loader(self):
        """
        Generates and returns a DataLoader for the validation data.
        """
        validation_subset = [self.graphs[i] for i in self.val_idxs]
        sampler      = RandomSampler(validation_subset, replacement=False)   
        return  DataLoader(validation_subset, batch_size= self.batch_size, sampler = sampler,  drop_last=True)

    def get_test_loader(self):
        """
        Generates and returns a DataLoader for the test data.
        """
        test_subset = [self.graphs[i] for i in self.test_idxs]
        sampler      = RandomSampler(test_subset, replacement=False)   
        return  DataLoader(test_subset, batch_size= self.batch_size, sampler = sampler,  drop_last=True)

def main():
    grafo_nx   = nx.read_gpickle( "./results/graphs/NX_recon_graph.gpickle")
    phe_L_c    = list(grafo_nx.nodes).index('phe_L_c')
    tyr_L_c    = list(grafo_nx.nodes).index('tyr_L_c')
    r0399      = list(grafo_nx.nodes).index('r0399')
    PHETHPTOX2 = list(grafo_nx.nodes).index('PHETHPTOX2')
    PYG_graph_only_Concen         = torch.load("./results/graphs/PYG_graph_only_Concen.pt")
    PYG_graph_only_Fluxes          = torch.load("./results/graphs/PYG_graph_only_Fluxes.pt")
    PYG_graph_Concen_plus_Fluxes  = torch.load("./results/graphs/PYG_graph_Concen_plus_Fluxes.pt") 


    first_partition , second_partition = bipartite.sets(grafo_nx)

    if first_partition.__len__() > second_partition.__len__():
        rxn_partition = first_partition
        met_partition = second_partition
    else:
        rxn_partition = second_partition 
        met_partition = first_partition


    partition_list =  np.array(list(nx.get_node_attributes(grafo_nx, "bipartite").values()))
    mask_rxns      =  partition_list.astype(bool)
    mask_mets      =  np.invert(partition_list.astype(bool))
    graphs_list_PYG_graph_only_Concen        = make_graphs_list(PYG_graph_only_Concen, target_list = [phe_L_c, tyr_L_c], mask_target = True)
    graphs_list_PYG_graph_only_Fluxes        = make_graphs_list(PYG_graph_only_Fluxes, target_list = [r0399, PHETHPTOX2], mask_target = True)
    graphs_list_PYG_graph_Concen_plus_Fluxes = make_graphs_list(PYG_graph_Concen_plus_Fluxes, 
                                                                target_list = [phe_L_c, tyr_L_c, r0399, PHETHPTOX2], mask_target = True)

    loader_only_Concen                 = BatchLoader(graphs_list_PYG_graph_only_Concen, batch_size= 4*32, validation_percent = .4)
    loader_only_Fluxes                 = BatchLoader(graphs_list_PYG_graph_only_Fluxes, batch_size= 4*32, validation_percent = .4)
    loader_Concen_plus_Fluxes          = BatchLoader(graphs_list_PYG_graph_Concen_plus_Fluxes, batch_size= 4*32, validation_percent = .4)




    x_loader_only_Concen = get_a_graph_from_loader(loader_only_Concen)


    assert np.unique(
        x_loader_only_Concen.x.reshape(len(mask_mets))[mask_mets][
        x_loader_only_Concen.x.reshape(len(mask_mets))[mask_mets] > 1e-10]).__len__() > 2

    assert np.unique(
        x_loader_only_Concen.x.reshape(len(mask_mets))[mask_mets][
        x_loader_only_Concen.x.reshape(len(mask_mets))[mask_mets] <= 1e-10]).__len__() >= 1

    #np.array([1.e-10]) in 
    assert np.unique(
        x_loader_only_Concen.x.reshape(len(mask_mets))[mask_mets][
        x_loader_only_Concen.x.reshape(len(mask_mets))[mask_mets] <= 1e-10]).__len__() <=2


    assert np.unique(
    x_loader_only_Concen.x.reshape(len(mask_mets))[mask_mets][
        x_loader_only_Concen.x.reshape(len(mask_mets))[mask_mets] <= 1e-10]).sum() < 1e-9


    assert np.unique(x_loader_only_Concen.x.reshape(len(mask_rxns))[mask_rxns]).__len__() == 1



    x_loader_only_Fluxes = get_a_graph_from_loader(loader_only_Fluxes)


    assert np.unique(x_loader_only_Fluxes.x.reshape(len(mask_mets))[mask_mets]).__len__() == 1
    assert np.unique(x_loader_only_Fluxes.x.reshape(len(mask_mets))[mask_rxns]).__len__() > 2



    x_loader_Concen_plus_Fluxes = get_a_graph_from_loader(loader_Concen_plus_Fluxes)


    assert np.unique(
        x_loader_Concen_plus_Fluxes.x.reshape(len(mask_mets))[mask_mets][
        x_loader_Concen_plus_Fluxes.x.reshape(len(mask_mets))[mask_mets] > 1e-10]).__len__() > 3


    assert np.unique(
        x_loader_Concen_plus_Fluxes.x.reshape(len(mask_mets))[mask_mets][
            np.invert(
        x_loader_Concen_plus_Fluxes.x.reshape(len(mask_mets))[mask_mets] > 1e-10)]
        ).__len__() <=2


    assert np.unique(
        x_loader_Concen_plus_Fluxes.x.reshape(len(mask_mets))[mask_mets][
            np.invert(
        x_loader_Concen_plus_Fluxes.x.reshape(len(mask_mets))[mask_mets] > 1e-10)]
        ).sum() < 1e-9


    assert np.unique(
        x_loader_Concen_plus_Fluxes.x.reshape(len(mask_mets))[mask_rxns][
        x_loader_Concen_plus_Fluxes.x.reshape(len(mask_mets))[mask_rxns] > 1e-10]).__len__() > 3

    torch.save(loader_only_Concen, "./results/dataloaders/MASKED_loader_only_Concen.pt")
    torch.save(loader_only_Fluxes, "./results/dataloaders/MASKED_loader_only_Fluxes.pt")
    torch.save(loader_Concen_plus_Fluxes, "./results/dataloaders/MASKED_loader_Concen_plus_Fluxes.pt")
# Call the main function
if __name__ == "__main__":
    main()