{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (custom_clss_and_fncs.py, line 49)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m/DeepenData/.miniconda/envs/geo/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3378\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0;36m  Cell \u001b[0;32mIn [1], line 1\u001b[0;36m\n\u001b[0;31m    from custom_clss_and_fncs import *\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m/DeepenData/Repos/geometric_cobra/src/custom_clss_and_fncs.py:49\u001b[0;36m\u001b[0m\n\u001b[0;31m    %matplotlib inline\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from custom_clss_and_fncs import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NX_fluxes_and_concentrations = nx.read_gpickle(\"./results/graphs_from_PYG_and_NX/NX_fluxes_and_concentrations.gpickle\")\n",
    "NX_only_concentrations       = nx.read_gpickle(\"./results/graphs_from_PYG_and_NX/NX_only_concentrations.gpickle\")\n",
    "pyg_graph_FplusC      = from_networkx(copy.deepcopy(nx.Graph(NX_fluxes_and_concentrations)))\n",
    "pyg_graph_onlyC       = from_networkx(copy.deepcopy(nx.Graph(NX_only_concentrations)))\n",
    "assert not pyg_graph_FplusC.is_directed()\n",
    "assert not pyg_graph_onlyC.has_isolated_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampled_metabolite_data         = pd.read_parquet(\"./results/data/oversampled_augmented_metabolite_data.parquet.gzip\")#\n",
    "labels                              = torch.tensor(oversampled_metabolite_data.label).reshape(len(oversampled_metabolite_data.label),1).int()\n",
    "assert set(labels.unique().numpy()) == set((1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from torch.utils.data import RandomSampler\n",
    "\n",
    "def make_graphs_list(pyg_graph,labels,mask_target:bool=False, target_node:int = 0, mask_number = 0):\n",
    "    pyg_graph.y = labels\n",
    "    graphs_list = []\n",
    "    for i in range(pyg_graph.x.shape[1]):\n",
    "    \n",
    "        \n",
    "        new_pyg_data  = Data(x =  pyg_graph.x[:,i].reshape(pyg_graph.num_nodes, 1),  y = pyg_graph.y[i], \n",
    "                            edge_index = pyg_graph.edge_index)\n",
    "        new_pyg_data.num_classes = 2\n",
    "        if mask_target:\n",
    "            new_pyg_data.x[target_node,:] = mask_number\n",
    "            \n",
    "        \n",
    "        graphs_list.append(new_pyg_data) \n",
    "    return graphs_list\n",
    "\n",
    "\n",
    "\n",
    "def make_loader(graphs: list, batch_size: int  =8*32):\n",
    "\n",
    "    sampler_train_set = RandomSampler(\n",
    "        graphs,\n",
    "        #num_samples= num_samples, #params[\"training\"][\"sampler_num_samples\"],  # Genera un muestreo del grafo\n",
    "        replacement=False,  # con repeticion de muestras\n",
    "    )\n",
    "    return DataLoader(graphs, batch_size=batch_size, sampler = sampler_train_set,  drop_last=True)\n",
    "\n",
    "graphs_list_only_concentrations       = make_graphs_list(pyg_graph_onlyC,labels)\n",
    "graphs_list_fluxes_and_concentrations = make_graphs_list(pyg_graph_FplusC,labels)\n",
    "\n",
    "\n",
    "loader_onlyC  = make_loader(graphs_list_only_concentrations)\n",
    "loader_FplusC = make_loader(graphs_list_fluxes_and_concentrations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classsifiers(X, y):\n",
    "    \n",
    "\n",
    "    #clf1 = LogisticRegression()\n",
    "    #clf2 = DecisionTreeClassifier()\n",
    "    clf3 = RandomForestClassifier()\n",
    "    clf4 = SVC(gamma='auto')\n",
    "    clf5 = GaussianNB()\n",
    "    clf6 = MLPClassifier()\n",
    "\n",
    "    gs = gridspec.GridSpec(3, 2)\n",
    "    fig = plt.figure(figsize=(14,7))\n",
    "    labels = ['Random Forest', 'SVM', 'Naive Bayes', 'Neural Network']\n",
    "    for clf, lab, grd in zip([clf3, clf4, clf5, clf6],\n",
    "                            labels,\n",
    "                            [(0,0), (0,1), (1,0), (1,1)]):\n",
    "        clf.fit(X, y)\n",
    "        ax = plt.subplot(gs[grd[0], grd[1]])\n",
    "        fig = plot_decision_regions(X=X, y=y, clf=clf, legend=2)\n",
    "        plt.title(lab)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "def train_classifiers_with_dataloader(loader):   \n",
    "    \n",
    "    contatenated = torch.Tensor()\n",
    "    labels_from_loader       = torch.Tensor()\n",
    "\n",
    "    for data in loader:  # Iterate in batches over the training dataset.\n",
    "            #data.to('cuda')\n",
    "            #out = model(data.x, data.edge_index, data.batch)\n",
    "            reshaped_batch     = data.x.reshape(data.y.shape[0], -1)\n",
    "            contatenated       = torch.cat((contatenated,reshaped_batch),0)        \n",
    "            labels_from_loader = torch.cat((labels_from_loader, data.y),0)\n",
    "            \n",
    "\n",
    "    non_zero_cols =  np.sum(contatenated.numpy() , 0) !=0\n",
    "    X_from_loader = contatenated[:,non_zero_cols]\n",
    "\n",
    "    reducer = umap.UMAP()\n",
    "    embedding = reducer.fit_transform(X_from_loader)\n",
    "    plot_classsifiers(embedding, labels_from_loader.to(int).numpy())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classifiers_with_dataloader(loader_onlyC)\n",
    "train_classifiers_with_dataloader(loader_FplusC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "target_node = \"phe_L_c\"\n",
    "assert list(NX_only_concentrations.nodes).index(target_node) == list(NX_fluxes_and_concentrations.nodes).index(target_node)\n",
    "phe_L_c_idx = list(NX_only_concentrations.nodes).index(target_node)\n",
    "\n",
    "\n",
    "graphs_list_only_concentrations_MASKED       = make_graphs_list(pyg_graph_onlyC,labels, mask_target = True, target_node = phe_L_c_idx)\n",
    "graphs_list_fluxes_and_concentrations_MASKED = make_graphs_list(pyg_graph_FplusC,labels, mask_target = True, target_node = phe_L_c_idx)\n",
    "\n",
    "\n",
    "loader_onlyC_MASKED  = make_loader(graphs_list_only_concentrations_MASKED)\n",
    "loader_FplusC_MASKED = make_loader(graphs_list_fluxes_and_concentrations_MASKED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classifiers_with_dataloader(loader_onlyC_MASKED)\n",
    "train_classifiers_with_dataloader(loader_FplusC_MASKED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('geo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ccb92c3caf64d15d8cccade25008a463e602c087926676408820d80b4769698"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
