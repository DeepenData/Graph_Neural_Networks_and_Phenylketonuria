{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/DeepenData/.miniconda/envs/geo/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling...\n",
      " A: min|aij| =  1.000e+00  max|aij| =  1.000e+00  ratio =  1.000e+00\n",
      "Problem data seem to be well scaled\n"
     ]
    }
   ],
   "source": [
    "from acevedo_clss_and_fcns import * \n",
    "model                                 = load_json_model(\"./COBRA_models/GEM_Recon2_thermocurated_redHUMAN.json\")\n",
    "feature_data                          = pd.read_parquet(\"./results/data/oversampled_augmented_metabolite_data.parquet.gzip\")#\n",
    "feature_names                         = pd.read_csv(\"./results/data/metabolite_names.csv\")\n",
    "grafo_nx             = cobra_to_networkx(model)\n",
    "grafo_nx_onlyConcen  = add_metabolite_concentration_features(grafo_nx, feature_data, feature_names)\n",
    "pyg_graph_onlyConcen = make_PYG_graph_from_grafo_nx(grafo_nx_onlyConcen)\n",
    "labels                 = torch.tensor(feature_data.label).reshape(len(feature_data.label),1)\n",
    "pyg_graph_onlyConcen.y = labels\n",
    "#torch.save(pyg_graph_onlyConcen, \"./results/graphs_from_PYG_and_NX/PYG_graph_only_Concen.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_graphs_list(pyg_graph_in,mask_target:bool=False, target_node:int = 0, mask_number = 0):\n",
    "    \n",
    "    pyg_graph = copy.deepcopy(pyg_graph_in)\n",
    "    graphs_list = []\n",
    "    \n",
    "    \n",
    "    for i in range(pyg_graph.x.shape[1]):\n",
    "    \n",
    "        \n",
    "        new_pyg_data  = Data(x =  pyg_graph.x[:,i].reshape(pyg_graph.num_nodes, 1),  y = pyg_graph.y[i], \n",
    "                            edge_index = pyg_graph.edge_index)\n",
    "        new_pyg_data.num_classes = 2\n",
    "        if mask_target:\n",
    "            new_pyg_data.x[target_node,:] = mask_number        \n",
    "        \n",
    "        graphs_list.append(new_pyg_data) \n",
    "    return graphs_list\n",
    "\n",
    "class batch_loader():\n",
    "    \n",
    "    def __init__(self, graphs: list, batch_size: int  =1*32, num_samples:int = None, validation_percent:float = .3):\n",
    "        self.graphs = graphs\n",
    "        self.batch_size = batch_size\n",
    "        self.num_samples = num_samples\n",
    "        self.validation_percent = validation_percent\n",
    "        self.train_idxs, self.val_idxs = train_test_split(range(len(self.graphs)), test_size = self.validation_percent)     \n",
    "        \n",
    "    def get_train_loader(self):\n",
    "        train_subset = [self.graphs[i] for i in self.train_idxs]\n",
    "        sampler      = RandomSampler(\n",
    "        train_subset,\n",
    "        #num_samples= self.num_samples, \n",
    "        replacement=False)   \n",
    "        \n",
    "        return  DataLoader(train_subset, batch_size= self.batch_size, sampler = sampler,  drop_last=True)\n",
    "    \n",
    "    def get_validation_loader(self):\n",
    "        validation_subset = [self.graphs[i] for i in self.val_idxs]\n",
    "        sampler      = RandomSampler(\n",
    "        validation_subset,\n",
    "        #num_samples= self.num_samples, \n",
    "        replacement=False)   \n",
    "        \n",
    "        return  DataLoader(validation_subset, batch_size= self.batch_size, sampler = sampler,  drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs_list_PYG_graph_only_Concen = make_graphs_list(pyg_graph_onlyConcen)\n",
    "\n",
    "loader = batch_loader(graphs_list_PYG_graph_only_Concen, batch_size= 64, validation_percent = .35)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7572"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_loader(graphs: list, batch_size: int  =1*32, num_samples:int = None):#, num_samples:int = 20*32):#batch_size: int  =8*32):\n",
    "\n",
    "    sampler_train_set = RandomSampler(\n",
    "        graphs,\n",
    "        #num_samples= num_samples, #params[\"training\"][\"sampler_num_samples\"],  # Genera un muestreo del grafo\n",
    "        replacement=False,  # con repeticion de muestras\n",
    "    )\n",
    "    return DataLoader(graphs, batch_size=batch_size, sampler = sampler_train_set,  drop_last=True)\n",
    "\n",
    "\n",
    "loader_only_Concen   = make_loader(graphs_list_PYG_graph_only_Concen)\n",
    "len(list(loader_only_Concen.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Acc: 0.6769, Test Acc: 0.6620\n",
      "Epoch: 002, Train Acc: 0.9484, Test Acc: 0.9506\n",
      "Epoch: 003, Train Acc: 0.9305, Test Acc: 0.9283\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache() \n",
    "#loader = loader_only_Concen\n",
    "model    = GCN(hidden_channels=8)\n",
    "optimizer     = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.NLLLoss()\n",
    "def train():\n",
    "    model.to('cuda')\n",
    "    model.train()\n",
    "\n",
    "    for data in loader.get_train_loader():  # Iterate in batches over the training dataset.\n",
    "         data.to('cuda')\n",
    "         out = model(data.x, data.edge_index, data.batch)  # Perform a single forward pass.\n",
    "         loss = criterion(out, data.y)  # Compute the loss.\n",
    "         loss.backward()  # Derive gradients.\n",
    "         optimizer.step()  # Update parameters based on gradients.\n",
    "         optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "def test(loader):\n",
    "     model.eval()\n",
    "     model.to('cuda')\n",
    "     correct = 0\n",
    "     for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "         data.to('cuda')\n",
    "         out = model(data.x, data.edge_index, data.batch)  \n",
    "         pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "         correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "     return correct / len(loader.dataset)  # Derive ratio of correct predictions.\n",
    "\n",
    "\n",
    "for epoch in range(1, 4):\n",
    "    train()\n",
    "    train_acc = test(loader.get_train_loader())\n",
    "    test_acc = test(loader.get_validation_loader())\n",
    "    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device = 'cuda:0'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:21<01:04, 21.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new best_val_model best_vloss = 0.9354960392304791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:26<01:19, 26.44s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [39], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m optimizer     \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m)\n\u001b[1;32m     12\u001b[0m loss_function \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mNLLLoss()\n\u001b[0;32m---> 13\u001b[0m best_val_model, last_best_state_dict_path, last_best_model_path \u001b[39m=\u001b[39m  train_and_validate(\n\u001b[1;32m     14\u001b[0m                                     model,loss_function,optimizer, EPOCHS \u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m ,\n\u001b[1;32m     15\u001b[0m                                     train_loader\u001b[39m=\u001b[39;49m loader\u001b[39m.\u001b[39;49mget_train_loader(),\n\u001b[1;32m     16\u001b[0m                                     validation_loader\u001b[39m=\u001b[39;49m loader\u001b[39m.\u001b[39;49mget_validation_loader(),\n\u001b[1;32m     17\u001b[0m                                     save_state_dict \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m,save_entire_model\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     18\u001b[0m                                     verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     19\u001b[0m                                     saving_path \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mresults\u001b[39;49m\u001b[39m'\u001b[39;49m, device\u001b[39m=\u001b[39;49mdevice)\n",
      "File \u001b[0;32m/DeepenData/Repos/geometric_cobra/src/acevedo_clss_and_fcns.py:432\u001b[0m, in \u001b[0;36mtrain_and_validate\u001b[0;34m(modelo, loss_fun, optimizer, EPOCHS, train_loader, validation_loader, validation_cycle, save_state_dict, save_entire_model, verbose, device, n_batches_report, saving_path, tunning_mode)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m tqdm\u001b[39m.\u001b[39mtqdm(\u001b[39mrange\u001b[39m(EPOCHS)):\n\u001b[1;32m    431\u001b[0m     modelo\u001b[39m.\u001b[39mtrain(\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 432\u001b[0m     avg_loss  \u001b[39m=\u001b[39m train_one_epoch(modelo, optimizer,train_loader, loss_fun, scaler, swa_start, swa_model, swa_scheduler, scheduler,\n\u001b[1;32m    433\u001b[0m                                 n_batches_report \u001b[39m=\u001b[39;49m n_batches_report, device\u001b[39m=\u001b[39;49mdevice) \n\u001b[1;32m    434\u001b[0m     \u001b[39mif\u001b[39;00m epoch \u001b[39m%\u001b[39m validation_cycle \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    435\u001b[0m         avg_vloss \u001b[39m=\u001b[39m validate(modelo, loss_fun, validation_loader, device\u001b[39m=\u001b[39mdevice )                \n",
      "File \u001b[0;32m/DeepenData/Repos/geometric_cobra/src/acevedo_clss_and_fcns.py:338\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(modelo, optimizer, train_loader, loss_fun, scaler, swa_start, swa_model, swa_scheduler, scheduler, n_batches_report, device)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m data\u001b[39m.\u001b[39mis_cuda   \n\u001b[1;32m    337\u001b[0m \u001b[39mif\u001b[39;00m (device \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcuda:0\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m|\u001b[39m (device \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m):                            \n\u001b[0;32m--> 338\u001b[0m     data\u001b[39m.\u001b[39;49mto(device, non_blocking\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m) \n\u001b[1;32m    339\u001b[0m     \u001b[39massert\u001b[39;00m data\u001b[39m.\u001b[39mis_cuda\n\u001b[1;32m    342\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad(set_to_none\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39m# Zero your gradients for every batch\u001b[39;00m\n",
      "File \u001b[0;32m/DeepenData/.miniconda/envs/geo/lib/python3.9/site-packages/torch_geometric/data/data.py:216\u001b[0m, in \u001b[0;36mBaseData.to\u001b[0;34m(self, device, non_blocking, *args)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto\u001b[39m(\u001b[39mself\u001b[39m, device: Union[\u001b[39mint\u001b[39m, \u001b[39mstr\u001b[39m], \u001b[39m*\u001b[39margs: List[\u001b[39mstr\u001b[39m],\n\u001b[1;32m    213\u001b[0m        non_blocking: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    214\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Performs tensor device conversion, either for all attributes or\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[39m    only the ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply(\n\u001b[1;32m    217\u001b[0m         \u001b[39mlambda\u001b[39;49;00m x: x\u001b[39m.\u001b[39;49mto(device\u001b[39m=\u001b[39;49mdevice, non_blocking\u001b[39m=\u001b[39;49mnon_blocking), \u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m/DeepenData/.miniconda/envs/geo/lib/python3.9/site-packages/torch_geometric/data/data.py:199\u001b[0m, in \u001b[0;36mBaseData.apply\u001b[0;34m(self, func, *args)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"Applies the function :obj:`func`, either to all attributes or only\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[39mthe ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39mfor\u001b[39;00m store \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstores:\n\u001b[0;32m--> 199\u001b[0m     store\u001b[39m.\u001b[39;49mapply(func, \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    200\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/DeepenData/.miniconda/envs/geo/lib/python3.9/site-packages/torch_geometric/data/storage.py:148\u001b[0m, in \u001b[0;36mBaseStorage.apply\u001b[0;34m(self, func, *args)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"Applies the function :obj:`func`, either to all attributes or only\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[39mthe ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems(\u001b[39m*\u001b[39margs):\n\u001b[0;32m--> 148\u001b[0m     \u001b[39mself\u001b[39m[key] \u001b[39m=\u001b[39m recursive_apply(value, func)\n\u001b[1;32m    149\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/DeepenData/.miniconda/envs/geo/lib/python3.9/site-packages/torch_geometric/data/storage.py:498\u001b[0m, in \u001b[0;36mrecursive_apply\u001b[0;34m(data, func)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrecursive_apply\u001b[39m(data: Any, func: Callable) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    497\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, Tensor):\n\u001b[0;32m--> 498\u001b[0m         \u001b[39mreturn\u001b[39;00m func(data)\n\u001b[1;32m    499\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mrnn\u001b[39m.\u001b[39mPackedSequence):\n\u001b[1;32m    500\u001b[0m         \u001b[39mreturn\u001b[39;00m func(data)\n",
      "File \u001b[0;32m/DeepenData/.miniconda/envs/geo/lib/python3.9/site-packages/torch_geometric/data/data.py:217\u001b[0m, in \u001b[0;36mBaseData.to.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto\u001b[39m(\u001b[39mself\u001b[39m, device: Union[\u001b[39mint\u001b[39m, \u001b[39mstr\u001b[39m], \u001b[39m*\u001b[39margs: List[\u001b[39mstr\u001b[39m],\n\u001b[1;32m    213\u001b[0m        non_blocking: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    214\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Performs tensor device conversion, either for all attributes or\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[39m    only the ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply(\n\u001b[0;32m--> 217\u001b[0m         \u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39;49mto(device\u001b[39m=\u001b[39;49mdevice, non_blocking\u001b[39m=\u001b[39;49mnon_blocking), \u001b[39m*\u001b[39margs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.init()\n",
    "    if torch.cuda.is_initialized():\n",
    "        device = 'cuda:0'\n",
    "\n",
    "print(f\"{device = }\")\n",
    "a_batch         = next(iter(loader.get_train_loader()))\n",
    "a_graph         = a_batch[0]\n",
    "model          = GIN_classifier(0, a_graph.num_nodes, a_graph.num_node_features)\n",
    "optimizer     = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_function = torch.nn.NLLLoss()\n",
    "best_val_model, last_best_state_dict_path, last_best_model_path =  train_and_validate(\n",
    "                                    model,loss_function,optimizer, EPOCHS =4 ,\n",
    "                                    train_loader= loader.get_train_loader(),\n",
    "                                    validation_loader= loader.get_validation_loader(),\n",
    "                                    save_state_dict = False,save_entire_model=False,\n",
    "                                    verbose=True,\n",
    "                                    saving_path = 'results', device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('geo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ccb92c3caf64d15d8cccade25008a463e602c087926676408820d80b4769698"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
