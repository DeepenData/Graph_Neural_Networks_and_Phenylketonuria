{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/DeepenData/.miniconda/envs/geo/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No defined compartments in model model. Compartments will be deduced heuristically using regular expressions.\n",
      "Using regular expression found the following compartments:c, e, g, i, l, m, n, r, x\n"
     ]
    }
   ],
   "source": [
    "from acevedo_clss_and_fcns import * \n",
    "from    cobra.io.mat import *\n",
    "from networkx.algorithms import bipartite\n",
    "def check_Concen_plus_Fluxes(a_graph, mask_mets, mask_rxns):\n",
    "    \n",
    "\n",
    "    assert np.unique(\n",
    "        a_graph.x.reshape(len(mask_mets))[mask_mets][\n",
    "        a_graph.x.reshape(len(mask_mets))[mask_mets] > 1e-10]).__len__() > 3\n",
    "\n",
    "    assert np.unique(\n",
    "        a_graph.x.reshape(len(mask_mets))[mask_mets][\n",
    "            np.invert(\n",
    "        a_graph.x.reshape(len(mask_mets))[mask_mets] > 1e-10)]\n",
    "        ).__len__() <=2\n",
    "\n",
    "    assert np.unique(\n",
    "        a_graph.x.reshape(len(mask_mets))[mask_mets][\n",
    "            np.invert(\n",
    "        a_graph.x.reshape(len(mask_mets))[mask_mets] > 1e-10)]\n",
    "        ).sum() < 1e-9\n",
    "\n",
    "    assert np.unique(\n",
    "        a_graph.x.reshape(len(mask_mets))[mask_rxns][\n",
    "        a_graph.x.reshape(len(mask_mets))[mask_rxns] > 1e-10]).__len__() > 3\n",
    "\n",
    "\n",
    "model = load_matlab_model(\"./COBRA_models/GEM_Recon3_thermocurated_redHUMAN_AA.mat\")\n",
    "rxn_list_recon: list[str] = [model.reactions[i].id       for i in range(model.reactions.__len__())]\n",
    "met_list_recon: list[str] = [model.metabolites[i].id     for i in range(model.metabolites.__len__())]\n",
    "\n",
    "G = nx.read_gpickle(\"./results/graphs/NX_recon_graph.gpickle\")\n",
    "\n",
    "\n",
    "partition_list =  np.array(list(nx.get_node_attributes(G, \"bipartite\").values()))\n",
    "mask_rxns      =  partition_list.astype(bool)\n",
    "mask_mets      =  np.invert(partition_list.astype(bool))\n",
    "\n",
    "def get_a_graph_from_loader(loader):\n",
    "    \n",
    "    #loader   = loader_only_Concen #torch.load(loader_path)\n",
    "    a_batch  = next(iter(loader.get_train_loader()))\n",
    "    return a_batch[0]\n",
    "\n",
    "Concen_plus_Fluxes = get_a_graph_from_loader(torch.load('./results/dataloaders/MASKED_loader_Concen_plus_Fluxes.pt'))\n",
    "\n",
    "check_Concen_plus_Fluxes(Concen_plus_Fluxes, mask_mets, mask_rxns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_averages(loader):    \n",
    "\n",
    "    control_list = []\n",
    "    pku_list     = []\n",
    "\n",
    "    for graph in loader.dataset[0:1000]:\n",
    "        \n",
    "        if graph.y.item() == 0:   \n",
    "            control_list.append(graph.x) \n",
    "            \n",
    "        elif graph.y.item() == 1:\n",
    "            pku_list.append(graph.x) \n",
    "    \n",
    "    return torch.cat(control_list, dim=1).mean(axis = 1),  torch.cat(pku_list, dim=1).mean(axis = 1)\n",
    "\n",
    "\n",
    "CONTROL_only_Concen, PKU_only_Concen = get_averages( torch.load('./results/dataloaders/MASKED_loader_only_Concen.pt').get_train_loader())\n",
    "CONTROL_only_Fluxes, PKU_only_Fluxes = get_averages( torch.load('./results/dataloaders/MASKED_loader_only_Fluxes.pt').get_train_loader())\n",
    "CONTROL_Concen_plus_Fluxes, PKU_Concen_plus_Fluxes = get_averages( torch.load('./results/dataloaders/MASKED_loader_Concen_plus_Fluxes.pt').get_train_loader())\n",
    "\n",
    "nx_Conc    = copy.deepcopy(nx.read_gpickle(\"./results/graphs/NX_recon_graph.gpickle\"))\n",
    "nx_Flux    = copy.deepcopy(nx.read_gpickle(\"./results/graphs/NX_recon_graph.gpickle\"))\n",
    "nx_ConFlux = copy.deepcopy(nx.read_gpickle(\"./results/graphs/NX_recon_graph.gpickle\"))\n",
    "\n",
    "def set_control_pku_features(G, control_tensor, pku_tensor):\n",
    "    \n",
    "\n",
    "    control_dict   = dict(zip(G,  control_tensor.tolist()))\n",
    "    pku_dict       = dict(zip(G,  pku_tensor.tolist()))\n",
    "\n",
    "\n",
    "    nx.set_node_attributes(G, control_dict, \"control\")\n",
    "    nx.set_node_attributes(G, pku_dict, \"pku\")\n",
    "\n",
    "\n",
    "set_control_pku_features(nx_Conc, CONTROL_only_Concen, PKU_only_Concen)\n",
    "set_control_pku_features(nx_Flux, CONTROL_only_Fluxes, PKU_only_Fluxes)\n",
    "set_control_pku_features(nx_ConFlux, CONTROL_Concen_plus_Fluxes, PKU_Concen_plus_Fluxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabolites = pd.read_csv(\"./metabolite_raw_data/metabolite_names.csv\").Recon3_ID\n",
    "metabolites = metabolites[[m in list(G.nodes) for m in metabolites]].tolist()\n",
    "assert set(metabolites).issubset(set(list(G.nodes)))\n",
    "\n",
    "mets_bool = [bool(re.search(\"crn_c|\\\\d+dc_c\", s)) for s in metabolites]\n",
    "\n",
    "\n",
    "AAs       = list(itertools.compress(metabolites, np.invert(mets_bool)))\n",
    "ACs       = list(itertools.compress(metabolites, mets_bool))\n",
    "\n",
    "base_dict =  dict(zip(G,   itertools.repeat(0)))\n",
    "AAs_dict  =  dict(zip(AAs, itertools.repeat(1)))\n",
    "ACs_dict  =  dict(zip(ACs, itertools.repeat(2)))\n",
    "\n",
    "colors_dict = copy.deepcopy(base_dict)\n",
    "\n",
    "colors_dict.update(AAs_dict)\n",
    "colors_dict.update(ACs_dict)\n",
    "\n",
    "nx.set_node_attributes(nx_Conc, colors_dict, \"color\")\n",
    "nx.write_gexf(nx_Conc, \"./results/graphs/for_visualizations/nx_Conc.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No defined compartments in model model. Compartments will be deduced heuristically using regular expressions.\n",
      "Using regular expression found the following compartments:c, e, g, i, l, m, n, r, x\n"
     ]
    }
   ],
   "source": [
    "model = load_matlab_model(\"./COBRA_models/GEM_Recon3_thermocurated_redHUMAN_AA.mat\")\n",
    "import re\n",
    "rxns        = [ r.id for r in model.reactions]\n",
    "subsystems  = [s.subsystem for s in model.reactions]\n",
    "subsys_bool = [bool(re.search(\"Phenyla|phenyla|Tetrahydrobiopterin\", s)) for s in subsystems[0:10600]]\n",
    "\n",
    "subsys_rxns = list(itertools.compress(rxns, subsys_bool))\n",
    "\n",
    "Phe_THBPT_rxns = ['r0399',\"DHPR\", \"DHPR2\", \"THBPT4ACAMDASE\", \"HMR_6728\", \"r0403\", \"r0398\", 'DHPR2',\n",
    " 'PHETA1m', 'PHYCBOXL', 'PPOR', 'PTHPS', 'THBPT4ACAMDASE', 'r0403', 'r0545', 'r0547', 'PHLAC', 'DHPR', 'r0398', 'PHETA1', 'HMR_6770',  'HMR_6854', 'HMR_6874'\n",
    "                  ]\n",
    "\n",
    "\n",
    "ACYL_rxns = ['FAOXC14C12m', 'FAOXC14C14OHm', 'FAOXC162C142m', 'LNLCCPT2', 'C181OHc', 'C40CPT1', 'FAOXC3DC',\n",
    "          'CSNATr', 'C30CPT1', 'C140CPT1', 'C141CPT1', 'FAOXC12DCc', 'C121CPT1', 'ADRNCPT1', 'ARACHCPT1', 'C160CPT1', 'C161CPT1', 'C161CPT12', \n",
    "          'C180CPT1', 'C181CPT1', 'C204CPT1', 'C226CPT1', 'CLPNDCPT1', 'DMNONCOACRNCPT1', 'DMNONCOACRNCPT1', 'EICOSTETCPT1', 'OCTDECCPT1',\n",
    "          'OCD11COACPT1', 'C81CPT1', 'C80CPT1', 'C60CPT1', 'C51CPT1', 'C50CPT1']\n",
    "\n",
    "base_dict            =  dict(zip(G,   itertools.repeat(0)))\n",
    "Phe_THBPT_rxns_dict  =  dict(zip(Phe_THBPT_rxns, itertools.repeat(1)))\n",
    "ACYL_rxns_dict       =  dict(zip(ACYL_rxns, itertools.repeat(2)))\n",
    "\n",
    "rxns_colors_dict = copy.deepcopy(base_dict)\n",
    "rxns_colors_dict.update(Phe_THBPT_rxns_dict)\n",
    "rxns_colors_dict.update(ACYL_rxns_dict)\n",
    "\n",
    "nx.set_node_attributes(nx_Flux, rxns_colors_dict, \"rxns_colors\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_fluxes(G,patient_group, attribute_name):\n",
    "\n",
    "    nx_Flux_control_dict = nx.get_node_attributes(G, patient_group)\n",
    "    visible_rxns         = list(set(Phe_THBPT_rxns).union(set(ACYL_rxns)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    visible_subset_dict = {\n",
    "        key: nx_Flux_control_dict[key]\n",
    "\n",
    "        for key in visible_rxns\n",
    "    }\n",
    "\n",
    "    base_dict            =  dict(zip(G,   itertools.repeat(0.0)))\n",
    "    flux_dict            = copy.deepcopy(base_dict)\n",
    "    flux_dict.update(visible_subset_dict)\n",
    "    nx.set_node_attributes(G, flux_dict, attribute_name)\n",
    "\n",
    "\n",
    "mask_fluxes(nx_Flux,\"control\", \"control_FLUX_node_sizes\")\n",
    "mask_fluxes(nx_Flux,\"pku\",      \"pku_FLUX_node_sizes\")\n",
    "\n",
    "nx.write_gexf(nx_Flux, \"./results/graphs/for_visualizations/nx_Flux.gexf\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ccb92c3caf64d15d8cccade25008a463e602c087926676408820d80b4769698"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
