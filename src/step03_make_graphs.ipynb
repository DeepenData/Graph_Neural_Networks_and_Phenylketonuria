{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/DeepenData/.miniconda/envs/geo/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling...\n",
      " A: min|aij| =  1.000e+00  max|aij| =  1.000e+00  ratio =  1.000e+00\n",
      "Problem data seem to be well scaled\n"
     ]
    }
   ],
   "source": [
    "from acevedo_clss_and_fcns import * \n",
    "model                                 = load_json_model(\"./COBRA_models/GEM_Recon2_thermocurated_redHUMAN.json\")\n",
    "feature_data                          = pd.read_parquet(\"./results/dataframes/augmented_metabolite_data.parquet.gzip\")#\n",
    "feature_names                         = pd.read_csv(\"./metabolites_data/metabolite_names.csv\")\n",
    "grafo_nx             = cobra_to_networkx(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "w  = dict(zip(grafo_nx.edges() , itertools.repeat(1)))\n",
    "\n",
    "nx.set_edge_attributes(grafo_nx, w, \"weight\")\n",
    "\n",
    "assert 1 == np.unique(list(nx.get_edge_attributes(grafo_nx, \"weight\").values())).__len__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add concentrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sucaceto_c'} is not in Recon2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def get_largest_cc(G):\n",
    "    \n",
    "  largest_wcc = max(nx.connected_components(nx.Graph(G)), key=len)\n",
    "\n",
    "\n",
    "  # Create a subgraph SG based on G\n",
    "  SG = G.__class__()\n",
    "  SG.add_nodes_from((n, G.nodes[n]) for n in largest_wcc)\n",
    "\n",
    "\n",
    "  SG.add_edges_from((n, nbr, d)\n",
    "      for n, nbrs in G.adj.items() if n in largest_wcc\n",
    "      for nbr, d in nbrs.items() if nbr in largest_wcc)\n",
    "\n",
    "  SG.graph.update(G.graph)\n",
    "\n",
    "  assert G.nodes.__len__() >= SG.nodes.__len__()\n",
    "  assert G.edges.__len__() >= SG.edges.__len__()\n",
    "  assert SG.nodes.__len__() == len(largest_wcc)\n",
    "  #assert not SG.is_directed() \n",
    "  assert nx.is_connected(nx.Graph(SG))\n",
    "\n",
    "  return copy.deepcopy(SG)\n",
    "to_remove = pd.read_csv('./results/dataframes/to_remove.csv').loc[:,\"0\"].tolist()\n",
    "grafo_nx.remove_nodes_from(to_remove)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "grafo_nx = get_largest_cc(grafo_nx)\n",
    "\n",
    "nx.write_gpickle(grafo_nx, \"./results/graphs/NX_recon_graph.gpickle\")\n",
    "\n",
    "\n",
    "grafo_nx_onlyConcen  = add_metabolite_concentration_features(grafo_nx, feature_data, feature_names)\n",
    "print(f\"{set(feature_names.Recon3_ID) - set(list(grafo_nx_onlyConcen.nodes)).intersection(set(feature_names.Recon3_ID))} is not in Recon2\")\n",
    "\n",
    "\n",
    "pyg_graph_onlyConcen = make_PYG_graph_from_grafo_nx(grafo_nx_onlyConcen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels                 = torch.tensor(feature_data.label).reshape(len(feature_data.label),1)\n",
    "pyg_graph_onlyConcen.y = labels\n",
    "torch.save(pyg_graph_onlyConcen, \"./results/graphs/PYG_graph_only_Concen.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_samples  = pd.read_parquet(\"./results/flux/flux_samples.parquet.gzip\")\n",
    "grafo_nx_Concen_plus_Fluxes = add_flux_features(grafo_nx_onlyConcen, flux_samples, feature_data)\n",
    "pyg_graph_Concen_plus_Fluxes = make_PYG_graph_from_grafo_nx(grafo_nx_Concen_plus_Fluxes)\n",
    "pyg_graph_Concen_plus_Fluxes.y = labels\n",
    "torch.save(pyg_graph_Concen_plus_Fluxes, \"./results/graphs/PYG_graph_Concen_plus_Fluxes.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gpickle(grafo_nx_Concen_plus_Fluxes, \"./results/graphs/NX_graph_Concen_plus_Fluxes.gpickle\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('geo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ccb92c3caf64d15d8cccade25008a463e602c087926676408820d80b4769698"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
