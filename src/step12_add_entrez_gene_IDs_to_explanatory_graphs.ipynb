{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No defined compartments in model model. Compartments will be deduced heuristically using regular expressions.\n",
      "Using regular expression found the following compartments:c, e, g, i, l, m, n, r, x\n",
      "2023-06-19 19:51:12,411\tINFO worker.py:1518 -- Started a local Ray instance.\n",
      "2023-06-19 19:51:27,976\tINFO worker.py:1518 -- Started a local Ray instance.\n",
      "2023-06-19 19:51:37,146\tINFO worker.py:1518 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "import cobra\n",
    "from cobra.io import load_json_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ray\n",
    "#cobra_model = load_json_model(\"./COBRA_models/GEM_Recon3_thermocurated_redHUMAN_AA.json\")\n",
    "\n",
    "\n",
    "\n",
    "from cobra.io.mat import *\n",
    "#from itertools import compress\n",
    "\n",
    "\n",
    "\n",
    "cobra_model = load_matlab_model(\"./COBRA_models/GEM_Recon3_thermocurated_redHUMAN_AA.mat\")\n",
    "\n",
    "import itertools\n",
    "\n",
    "def grow_dict(previo, nuevo):  \n",
    "    \"\"\"Esto es un .update(overwritte=False)?\"\"\"\n",
    "\n",
    "    not_new_keys = set(previo.keys()).intersection(set(nuevo.keys()))\n",
    "    new_keys     = set(nuevo.keys()).difference(set(previo.keys()))\n",
    "    for new in new_keys:\n",
    "        previo[new] =np.unique(nuevo[new]).tolist() \n",
    "    for common in not_new_keys:\n",
    "        previo[common].extend(np.unique(nuevo[common]).tolist() )\n",
    "    return previo\n",
    "# Sacamos los genes de Recon hacia un diccionario\n",
    "# TODO: convertir est en una horrible dict_comprehension { curse : cursed for c in curseds }\n",
    "dict_rxn_to_gene = dict()\n",
    "genes            = [g.id for g in cobra_model.genes]\n",
    "\n",
    "for id in genes:\n",
    "    # fmt: off\n",
    "    rxns             = [r.id for r in cobra_model.genes.get_by_id(id)._reaction] # reacciones asociadas al gen de la iter\n",
    "    updated_dict  : dict[str, list[str]] = dict(zip(rxns,itertools.repeat([id]))) # zipping con la { reaccion : [id_gen] }\n",
    "    dict_rxn_to_gene = grow_dict(dict_rxn_to_gene, updated_dict) # merge recursivo\n",
    "    \n",
    "def get_data_for_heatmap(explanatory_subgraph_path):\n",
    "        \n",
    "    explanatory_subgraph = pd.read_parquet(explanatory_subgraph_path).reset_index(drop=True)\n",
    "\n",
    "    ray.shutdown()\n",
    "    ray.init()\n",
    "    @ray.remote\n",
    "\n",
    "\n",
    "    def get_genes(node_1, node_2):\n",
    "        \n",
    "        if node_2 in dict_rxn_to_gene.keys():\n",
    "            \n",
    "            return dict_rxn_to_gene[node_2]\n",
    "            \n",
    "        elif node_1 in dict_rxn_to_gene.keys():\n",
    "            \n",
    "            return dict_rxn_to_gene[node_1]\n",
    "            \n",
    "        else:\n",
    "            return ['']\n",
    "        \n",
    "    g = [] \n",
    "    for node_1, node_2 in zip(explanatory_subgraph.node1.tolist(), explanatory_subgraph.node2.tolist()):   \n",
    "        g.append(get_genes.remote(node_1, node_2 ))\n",
    "\n",
    "    \n",
    "    genes = pd.Series(ray.get(g) , name='genes')\n",
    "\n",
    "\n",
    "\n",
    "    assert genes.shape[0] == explanatory_subgraph.shape[0]\n",
    "\n",
    "\n",
    "    return pd.concat([genes, explanatory_subgraph], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "to_R_heatmap_explanatory_subgraph_MASKED_GIN_Fluxes = get_data_for_heatmap(\"./results/explanations/Explanatory_subgraph_MASKED_GIN_Fluxes.parquet.gzip\")\n",
    "to_R_heatmap_explanatory_subgraph_MASKED_GIN_Concentration = get_data_for_heatmap(\"./results/explanations/Explanatory_subgraph_MASKED_GIN_Concentration.parquet.gzip\")\n",
    "to_R_heatmap_explanatory_subgraph_MASKED_GIN_Concen_plus_Fluxes = get_data_for_heatmap(\"./results/explanations/Explanatory_subgraph_MASKED_GIN_Concen_plus_Fluxes.parquet.gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_R_heatmap_explanatory_subgraph_MASKED_GIN_Fluxes.reset_index(drop=True).to_csv(\n",
    "    \"./results/explanations/to_functional_R_heatmap_explanatory_subgraph_MASKED_GIN_Fluxes.csv\")\n",
    "to_R_heatmap_explanatory_subgraph_MASKED_GIN_Concentration.to_csv(\n",
    "    \"./results/explanations/to_functional_R_heatmap_explanatory_subgraph_MASKED_GIN_Concentration.csv\")\n",
    "to_R_heatmap_explanatory_subgraph_MASKED_GIN_Concen_plus_Fluxes.to_csv(\n",
    "    \"./results/explanations/to_functional_R_heatmap_explanatory_subgraph_MASKED_GIN_Concen_plus_Fluxes.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
