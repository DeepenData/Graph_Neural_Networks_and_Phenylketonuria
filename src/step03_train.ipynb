{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/DeepenData/.miniconda/envs/geo/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device = 'cuda:0'\n"
     ]
    }
   ],
   "source": [
    "from acevedo_clss_and_fcns import * \n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.init()\n",
    "    if torch.cuda.is_initialized():\n",
    "        device = 'cuda:0'\n",
    "#device = torch.device(device)\n",
    "print(f\"{device = }\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(modelo: GIN_classifier_to_explain,\n",
    "                    optimizer, \n",
    "                    train_loader: torch_geometric.loader.dataloader.DataLoader,\n",
    "                    loss_fun: torch.nn.modules.loss,\n",
    "                    device:str='cpu' ):\n",
    "\n",
    "    correct = 0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        assert not data.is_cuda   \n",
    "        if (device == 'cuda:0') | (device == 'cuda'):                            \n",
    "            data.to(device, non_blocking=True) \n",
    "            assert data.is_cuda       \n",
    "                \n",
    "        optimizer.zero_grad(set_to_none=True) # Zero your gradients for every batch        \n",
    "        if (device == 'cuda:0') | (device == 'cuda'):\n",
    "            #with torch.cuda.amp.autocast():      \n",
    "            predictions = modelo(data.x, data.edge_index,  None)# Make predictions for this batch\n",
    "            loss        = loss_fun(predictions, data.y)\n",
    "            loss.backward()  # Derive gradients.\n",
    "            optimizer.step()  # Update parameters based on gradients.        \n",
    "            pred     = predictions.argmax(dim=1)  # Use the class with highest probability.\n",
    "            correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "\n",
    "    return correct / len(train_loader.dataset)\n",
    "\n",
    "def validate(modelo: GIN_classifier_to_explain, loader: DataLoader, device: str = 'cpu'):\n",
    "    modelo.eval()\n",
    "    correct = 0\n",
    "    for i, val_data in enumerate(loader):\n",
    "        \n",
    "        assert not val_data.is_cuda\n",
    "        if (device == 'cuda:0') | (device == 'cuda'):\n",
    "            val_data.to(device, non_blocking=True) \n",
    "            assert val_data.is_cuda                          \n",
    "\n",
    "        val_predictions = modelo(val_data.x, val_data.edge_index, None)# Make predictions for this batch\n",
    "        pred            = val_predictions.argmax(dim=1)\n",
    "\n",
    "        correct += int((pred == val_data.y).sum())\n",
    "        \n",
    "\n",
    "    return correct / len(loader.dataset)   \n",
    "\n",
    "loader_path = \"./results/dataloaders/MASKED_loader_Concen_plus_Fluxes.pt\"\n",
    "\n",
    "loader = torch.load(loader_path)\n",
    "\n",
    "a_batch         = next(iter(loader.get_train_loader()))\n",
    "a_graph         = a_batch[0]\n",
    "\n",
    "batch_size      = len(a_batch.ptr)-1\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache() \n",
    "model           = GIN_classifier_to_explain(\n",
    "                                            batch_size=batch_size, \n",
    "                                            n_nodes = a_graph.num_nodes, \n",
    "                                            num_features = a_graph.num_node_features, \n",
    "                                            hidden_dim=16).to(device, non_blocking=True)\n",
    "optimizer       = torch.optim.Adam(model.parameters())\n",
    "loss_function   = torch.nn.NLLLoss()\n",
    "best_validation_accuracy = 1e-10\n",
    "EPOCHS = 220\n",
    "verbose = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saving_path   = \"results/trained_pytorch_models\"\n",
    "\n",
    "for epoch in tqdm.tqdm(range(EPOCHS)):\n",
    "    \n",
    "    train_accuracy = train_one_epoch(model,\n",
    "                        optimizer=optimizer, \n",
    "                        train_loader=loader.get_train_loader(),\n",
    "                        loss_fun=loss_function,\n",
    "                        device = device)\n",
    "\n",
    "    validation_accuracy = validate(model, loader.get_validation_loader(), device)\n",
    "    if validation_accuracy > best_validation_accuracy:\n",
    "        best_validation_accuracy = validation_accuracy\n",
    "        del validation_accuracy\n",
    "        best_val_state_dict   = copy.deepcopy(model.state_dict())\n",
    "        best_val_model        = copy.deepcopy(model)\n",
    "        if verbose:\n",
    "            timestamp     = datetime.now().strftime('%d-%m-%Y_%Hh_%Mmin')              \n",
    "            print(f'Epoch: {epoch:03d}, train_accuracy: {train_accuracy:.4f}, best_validation_accuracy: {best_validation_accuracy:.4f}')\n",
    "            model_path = saving_path+'/Model_{}_{}_best_ValAcc_{}_epoch_{}.pt'.format(model.__class__.__name__,timestamp, best_validation_accuracy, epoch)\n",
    "            torch.save(best_val_model, model_path)\n",
    "            print(f\"saved as {model_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp     = datetime.now().strftime('%d-%m-%Y_%Hh_%Mmin')   \n",
    "\n",
    "saving_path   = \"results/trained_pytorch_models\"\n",
    "\n",
    "model_path = saving_path+'/Model_{}_{}_best_ValAcc_{}_epoch_{}.pt'.format(model.__class__.__name__,timestamp, best_validation_accuracy, epoch)\n",
    "torch.save(best_val_model, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------end-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_train_validate_from_loader(loader_path, EPOCHS:int=10, device:str='cpu'):\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache() \n",
    "    loader = torch.load(loader_path)\n",
    "    a_batch         = next(iter(loader.get_train_loader()))\n",
    "    a_graph         = a_batch[0]\n",
    "    model          = GIN_classifier(0, a_graph.num_nodes, a_graph.num_node_features)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    criterion = torch.nn.NLLLoss()\n",
    "    def train(loader):\n",
    "        model.to(device)\n",
    "        model.train()\n",
    "\n",
    "        for data in loader:  # Iterate in batches over the training dataset.\n",
    "            data.to('cuda')\n",
    "            out = model(data)  # Perform a single forward pass.\n",
    "            loss = criterion(out, data.y)  # Compute the loss.\n",
    "            loss.backward()  # Derive gradients.\n",
    "            optimizer.step()  # Update parameters based on gradients.\n",
    "            optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "    def test(loader):\n",
    "        model.eval()\n",
    "        model.to(device)\n",
    "        correct = 0\n",
    "        for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "            data.to('cuda')\n",
    "            out = model(data)  \n",
    "            pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "            correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "        return correct / len(loader.dataset)  # Derive ratio of correct predictions.\n",
    "\n",
    "\n",
    "    for epoch in range(1, EPOCHS):\n",
    "        train(loader.get_train_loader())\n",
    "        train_acc = test(loader.get_train_loader())\n",
    "        test_acc = test(loader.get_validation_loader())\n",
    "        print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "        \n",
    "def Advanced_train_validate_from_loader(loader_path: str=None, EPOCHS:int=10, device:str='cpu'):\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache() \n",
    "    loader = torch.load(loader_path)\n",
    "\n",
    "    a_batch         = next(iter(loader.get_train_loader()))\n",
    "    a_graph         = a_batch[0]\n",
    "    model          = GIN_classifier(0, a_graph.num_nodes, a_graph.num_node_features)\n",
    "    optimizer     = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    loss_function = torch.nn.NLLLoss()\n",
    "    best_val_model, last_best_state_dict_path, last_best_model_path =  train_and_validate(\n",
    "                                        model,loss_function,optimizer, EPOCHS =EPOCHS ,\n",
    "                                        train_loader= loader.get_train_loader(),\n",
    "                                        validation_loader= loader.get_validation_loader(),\n",
    "                                        save_state_dict = False,save_entire_model=False,\n",
    "                                        verbose=True,\n",
    "                                        saving_path = 'results', device=device)\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('geo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ccb92c3caf64d15d8cccade25008a463e602c087926676408820d80b4769698"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
