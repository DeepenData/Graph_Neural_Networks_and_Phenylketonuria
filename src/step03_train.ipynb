{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device = 'cuda:0'\n"
     ]
    }
   ],
   "source": [
    "from custom_clss_and_fncs import * \n",
    "import torch\n",
    "import torch_geometric\n",
    "from datetime import datetime\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.init()\n",
    "    if torch.cuda.is_initialized():\n",
    "        device = 'cuda:0'\n",
    "#device = torch.device(device)\n",
    "print(f\"{device = }\")\n",
    "\n",
    "\n",
    "loader_onlyC = torch.load(\"./results/dataloaders/loader_onlyC.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7020, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model\n",
    "import torch.nn.functional as F\n",
    "class GIN_classifier(torch.nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        target_node_idx: int,\n",
    "        n_nodes : int, \n",
    "        num_features : int, \n",
    "        out_channels: int = 8,\n",
    "        dropout : float = 0.07, \n",
    "        hidden_dim : int = 8, \n",
    "        #heads : int = 5,\n",
    "        LeakyReLU_slope : float = 0.01,\n",
    "\n",
    "        num_layers: int = 4\n",
    "    ):\n",
    "        super(GIN_classifier, self).__init__() # TODO: why SUPER gato? \n",
    "        self.n_nodes = n_nodes\n",
    "        self.dropout = dropout\n",
    "        self.num_features = num_features\n",
    "        self.target_node_idx = target_node_idx\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        self.GIN_layers =  GIN(in_channels= num_features, hidden_channels= hidden_dim, num_layers= num_layers, \n",
    "                               out_channels= out_channels, dropout=dropout,  jk=None, act='LeakyReLU', act_first = True)\n",
    "        \n",
    "        \n",
    "        \n",
    "               \n",
    "        self.FC1        = Linear(in_features=out_channels, out_features=1, bias=True)\n",
    "        self.FC2        = Linear(in_features=self.n_nodes, out_features=2, bias=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #self.FC2        = Linear(in_features=n_nodes, out_features=1, bias=True)#.to('cuda')        #self.leakyrelu = LeakyReLU(LeakyReLU_slope).to('cuda')\n",
    "        self.leakyrelu = LeakyReLU(LeakyReLU_slope)#.to('cuda')\n",
    "    def forward(self, x):\n",
    "        data       = x.x \n",
    "        edge_index = x.edge_index\n",
    "        batch_size = x.y.shape[0]\n",
    "\n",
    "        x     = self.GIN_layers(data, edge_index)\n",
    "        x     = x.reshape(batch_size, self.n_nodes, self.out_channels)\n",
    "        x     = self.FC1(self.leakyrelu(x))\n",
    "        x     = x.reshape(batch_size,  self.n_nodes)              \n",
    "        x     = self.FC2(self.leakyrelu(x))\n",
    "        x     = x.reshape(batch_size, 2)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return   F.log_softmax(x, dim=1).squeeze()#x.squeeze() #x[:,self.target_node_idx,:].squeeze()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "a_batch         = next(iter(loader_onlyC))\n",
    "a_graph         = a_batch[0]\n",
    "model          = GIN_classifier(0, a_graph.num_nodes, a_graph.num_node_features)\n",
    "out           = model(a_batch)\n",
    "optimizer     = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_function = torch.nn.NLLLoss()\n",
    "#loss_fun      = torch.nn.MSELoss()\n",
    "\n",
    "loss_function(out, a_batch.y.long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(modelo: regresor_GIN_v3,\n",
    "                    optimizer, \n",
    "                    train_loader: torch_geometric.loader.dataloader.DataLoader,\n",
    "                    loss_fun: torch.nn.modules.loss,\n",
    "                    scaler:torch.cuda.amp.grad_scaler.GradScaler,\n",
    "                    swa_start:int,\n",
    "                    swa_model,swa_scheduler,scheduler, \n",
    "                    n_batches_report:int, device:str='cpu' ):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "    for i, data in enumerate(train_loader):\n",
    "        assert not data.is_cuda   \n",
    "        if (device == 'cuda:0') | (device == 'cuda'):                            \n",
    "            data.to(device, non_blocking=True) \n",
    "            assert data.is_cuda\n",
    "        \n",
    "                \n",
    "        optimizer.zero_grad(set_to_none=True) # Zero your gradients for every batch\n",
    "        \n",
    "        if (device == 'cuda:0') | (device == 'cuda'):\n",
    "            with torch.cuda.amp.autocast():      \n",
    "                predictions = modelo(data)# Make predictions for this batch\n",
    "                loss        = loss_fun(predictions, data.y.long())\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            if (i+1) % 2 == 0:  \n",
    "                if i > swa_start:\n",
    "                    swa_model.update_parameters(modelo)\n",
    "                    swa_scheduler.step()\n",
    "                else:\n",
    "                    scheduler.step()\n",
    "            \n",
    "            #check_seen_y.extend(data.y.squeeze().tolist())\n",
    "            #loss.backward()  # Derive gradients.\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            #optimizer.step()  # Update parameters based on gradients.\n",
    "                running_loss += loss.item()\n",
    "                 \n",
    "            \n",
    "        else:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                predictions = modelo(data)# Make predictions for this batch\n",
    "                loss        = loss_fun(predictions, data.y.long())\n",
    "            loss.backward()\n",
    "            if (i+1) % 2 == 0:  \n",
    "                if i > swa_start:\n",
    "                    swa_model.update_parameters(modelo)\n",
    "                    swa_scheduler.step()\n",
    "                else:\n",
    "                    scheduler.step()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()   \n",
    "            \n",
    "        \n",
    "    \n",
    "\n",
    "            \n",
    "        #It reports on the loss for every 100 batches.\n",
    "        if i % n_batches_report == 99:\n",
    "            last_loss = running_loss / n_batches_report\n",
    "            running_loss = 0.\n",
    "    torch.optim.swa_utils.update_bn(train_loader, swa_model, device=device)\n",
    "    return last_loss\n",
    "\n",
    "def validate(modelo: regresor_GIN_v3, loss_fun: torch.nn, loader: DataLoader, device: str = 'cpu'):\n",
    "    modelo.eval()\n",
    "    running_vloss = 0.0\n",
    "    for i, val_data in enumerate(loader):\n",
    "        \n",
    "        assert not val_data.is_cuda\n",
    "        if (device == 'cuda:0') | (device == 'cuda'):\n",
    "            val_data.to(device, non_blocking=True) \n",
    "            assert val_data.is_cuda\n",
    "                           \n",
    "        #val_data.to(device, non_blocking=True) \n",
    "\n",
    "        predictions = modelo(val_data)# Make predictions for this batch\n",
    "        val_loss    = loss_fun(predictions, val_data.y.long())\n",
    "        running_vloss += val_loss.item()\n",
    "        \n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    return avg_vloss   \n",
    "\n",
    "from torch.optim.swa_utils import SWALR\n",
    "import gc\n",
    "import tqdm\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()  \n",
    "  \n",
    "#optimizer     = torch.optim.Adam(modelo.parameters(),)\n",
    "\n",
    "def train_and_validate(modelo,loss_fun,optimizer, EPOCHS ,train_loader,validation_loader, \n",
    "                       validation_cycle:int = 4,\n",
    "                       save_state_dict:bool = False,save_entire_model:bool = False,verbose:bool= False,\n",
    "                       device:str='cpu', n_batches_report:int = 50, saving_path: str = '', tunning_mode:bool=False):\n",
    "    \n",
    "    modelo.to(device, non_blocking=True)\n",
    "    scaler        = torch.cuda.amp.GradScaler()\n",
    "    timestamp     = datetime.now().strftime('%d-%m-%Y_%Hh_%Mmin')    \n",
    "    swa_model     = torch.optim.swa_utils.AveragedModel(modelo).to(device, non_blocking=True)    \n",
    "    scheduler     = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=300)\n",
    "    swa_start     = 25\n",
    "    swa_scheduler = SWALR(optimizer, swa_lr=0.05)\n",
    "    epoch_number  = 0\n",
    "    best_vloss    = 1e10\n",
    "    state_dict_path = None\n",
    "    model_path      = None\n",
    "    for epoch in tqdm.tqdm(range(EPOCHS)):\n",
    "\n",
    "        modelo.train(True)\n",
    "        avg_loss  = train_one_epoch(modelo, optimizer,train_loader, loss_fun, scaler, swa_start, swa_model, swa_scheduler, scheduler,\n",
    "                                    n_batches_report = n_batches_report, device=device) \n",
    "        if epoch % validation_cycle == 0:\n",
    "            avg_vloss = validate(modelo, loss_fun, validation_loader, device=device )                \n",
    "        \n",
    "        \n",
    "        if avg_vloss < best_vloss:\n",
    "            best_vloss            = avg_vloss\n",
    "            best_val_state_dict   = copy.deepcopy(modelo.state_dict())\n",
    "            best_val_model        = copy.deepcopy(modelo)\n",
    "            if verbose:\n",
    "                print(f\"new best_val_model {best_vloss = }\")\n",
    "            \n",
    "            \n",
    "            if save_state_dict:\n",
    "                state_dict_path = saving_path+'/state_dicts/State_Dict_{}_{}_best_vloss_{}_epoch_{}'.format(\n",
    "                                                                modelo.__class__.__name__,timestamp, best_vloss, epoch_number)\n",
    "                torch.save(modelo.state_dict(), state_dict_path)\n",
    "                if verbose:\n",
    "                    print(f\"best state_dict saved as {state_dict_path}\")\n",
    "                    \n",
    "            if save_entire_model:\n",
    "                model_path = saving_path+'/models/Model_{}_{}_best_vloss_{}_epoch_{}.pt'.format(\n",
    "                                                                modelo.__class__.__name__,timestamp, best_vloss, epoch_number)\n",
    "                torch.save(best_val_model, model_path)\n",
    "                if verbose:\n",
    "                    print(f\"best model saved as {model_path}\")\n",
    "                \n",
    "                    \n",
    "        epoch_number += 1\n",
    "    #last_best_state_dict = copy.deepcopy(state_dict_path)\n",
    "    if tunning_mode:\n",
    "        return best_vloss\n",
    "        \n",
    "    return best_val_model, state_dict_path, model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:29<00:59, 29.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new best_val_model best_vloss = 0.7761029601097107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:56<00:27, 27.75s/it]"
     ]
    }
   ],
   "source": [
    "best_val_model, last_best_state_dict_path, last_best_model_path =  train_and_validate(\n",
    "                                    model,loss_function,optimizer, 3 ,\n",
    "                                    loader_onlyC,\n",
    "                                    loader_onlyC,\n",
    "                                    save_state_dict = False,save_entire_model=False,\n",
    "                                    verbose=True,\n",
    "                                    saving_path = 'results', device='cuda')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_one_epoch(modelo: GIN_classifier,\n",
    "                    optimizer, \n",
    "                    train_loader: torch_geometric.loader.dataloader.DataLoader,\n",
    "                    loss_fun: torch.nn.modules.loss,\n",
    "                    scaler:torch.cuda.amp.grad_scaler.GradScaler,\n",
    "                    swa_start:int,\n",
    "                    swa_model,swa_scheduler,scheduler, \n",
    "                    n_batches_report:int=50, device:str='cpu' ):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "    for i, data in enumerate(train_loader):\n",
    "        assert not data.is_cuda   \n",
    "        if (device == 'cuda:0') | (device == 'cuda'):                            \n",
    "            data.to(device, non_blocking=True) \n",
    "            assert data.is_cuda\n",
    "        \n",
    "                \n",
    "        optimizer.zero_grad(set_to_none=True) # Zero your gradients for every batch\n",
    "        \n",
    "        if (device == 'cuda:0') | (device == 'cuda'):\n",
    "            with torch.cuda.amp.autocast():      \n",
    "                predictions = modelo(data)# Make predictions for this batch\n",
    "                loss        = loss_fun(predictions, data.y.long())\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            if (i+1) % 2 == 0:  \n",
    "                if i > swa_start:\n",
    "                    swa_model.update_parameters(modelo)\n",
    "                    swa_scheduler.step()\n",
    "                else:\n",
    "                    scheduler.step()\n",
    "            \n",
    "            #check_seen_y.extend(data.y.squeeze().tolist())\n",
    "            #loss.backward()  # Derive gradients.\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            #optimizer.step()  # Update parameters based on gradients.\n",
    "                running_loss += loss.item()\n",
    "                 \n",
    "            \n",
    "        else:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                predictions = modelo(data)# Make predictions for this batch\n",
    "                loss        = loss_fun(predictions, data.y.long())\n",
    "            loss.backward()\n",
    "            if (i+1) % 2 == 0:  \n",
    "                if i > swa_start:\n",
    "                    swa_model.update_parameters(modelo)\n",
    "                    swa_scheduler.step()\n",
    "                else:\n",
    "                    scheduler.step()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()   \n",
    "            \n",
    "        \n",
    "    \n",
    "\n",
    "            \n",
    "        #It reports on the loss for every 100 batches.\n",
    "        if i % n_batches_report == 99:\n",
    "            last_loss = running_loss / n_batches_report\n",
    "            running_loss = 0.\n",
    "    torch.optim.swa_utils.update_bn(train_loader, swa_model, device=device)\n",
    "    return last_loss\n",
    "\n",
    "from torch.optim.swa_utils import SWALR\n",
    "\n",
    "\n",
    "model.to(device, non_blocking=True)\n",
    "scaler        = torch.cuda.amp.GradScaler()\n",
    "timestamp     = datetime.now().strftime('%d-%m-%Y_%Hh_%Mmin')    \n",
    "swa_model     = torch.optim.swa_utils.AveragedModel(model).to(device, non_blocking=True)    \n",
    "scheduler     = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=300)\n",
    "swa_start     = 25\n",
    "swa_scheduler = SWALR(optimizer, swa_lr=0.05)\n",
    "epoch_number  = 0\n",
    "best_vloss    = 1e10\n",
    "state_dict_path = None\n",
    "model_path      = None\n",
    "\n",
    "train_one_epoch(model, optimizer, loader_onlyC, loss_function,scaler,swa_start,\n",
    "                swa_model, swa_scheduler, scheduler, 50, 'cuda')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('geo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ccb92c3caf64d15d8cccade25008a463e602c087926676408820d80b4769698"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
